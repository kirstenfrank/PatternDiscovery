---
title: "PatternDiscoveryTools"
author: "Kirsten Frank"
date: "February 22, 2015"
output: html_document
---

Coursera Course Pattern Discovery in Data Mining. I am TAing this course and I want to implement some of the tools in R.

First, we need to make a small database that looks like the database of supermarket transactions. 


Small Patterns
==============

```{r Generate small basket}
set.seed(123)
Itemlist<-c("Beer","Coffee","Nuts","Diapers","Milk","Bread","Wine","Cheese","HotDogs","Steak","Ketchup","Mustard")
library(arules)
N<-80   #Number of transactions
size_transaction<-sample(2:10,N,replace=TRUE)
DB<-list()
for (i in 1:length(size_transaction))
    {
    newtransactionDB<-sample(Itemlist,size_transaction[i],replace=FALSE)
    DB[i]<-list(newtransactionDB)  # Fill in the database as a list of lists.
}

##This finally works. It generates N transactions from the ItemList without duplicates.

transDB<-as(DB,"transactions")  ##Convert to a Matrix that Arules expects.
```
Then we use the arules package tools to mine the database. 


```{r mine the database}
freqset <-eclat(transDB, parameter=
                    list(support=0.30, minlen =1))
## find frequent itemsets using ECLAT algorithm

inspect(freqset)

rules<-apriori(transDB,parameter=
                   list(support=0.30,
                        confidence =0.4,
                        minlen =2))

inspect(rules)
```

After getting the database and mining it, we can pull some of the information out of the rules object that we created. 

```{r subset or sort rules}
inspect(sort(rules, by = "confidence"))
rules.sub<-subset(rules,subset=confidence > 0.64)
interestMeasure(rules,method=c("cosine","chiSquared"),transDB)
```
Colossal Patterns
===================

Now, to generate two colossal patterns and hide them in a transaction database. One will be 65 items and the other will be 75 items.



```{r colossal pattern generation}
library(arules)
items<-combn(letters,2)  ## Make list of possible combinations of 2 letters
items<-paste(items[1,],items[2,],sep="")  ## Paste them together to make a item.
largepattern1<-sample(items,75,replace=FALSE)
largepattern2<-sample(items,65,replace=FALSE)
freqlarge1<-20
freqlarge2<-25
N<-100
size_transaction<-sample(60:80,N,replace=TRUE)
DBcolossal<-list()
DBcolossal[1:freqlarge1]<-rep(list(largepattern1),freqlarge1)   ## Fill first slots with Pattern 1
DBcolossal[(freqlarge1+1):(freqlarge1+freqlarge2)]<- rep(list(largepattern2),freqlarge2)  ## Fill more slots with Pattern 2
for (i in (freqlarge1+freqlarge2+1):length(size_transaction))
    {
    newtransactionDB<-sample(items,size_transaction[i],replace=FALSE)
    DBcolossal[i]<-list(newtransactionDB)
}    ## Fill remainder with random selections from items.
transcolDB<-as(DBcolossal,"transactions")
```

Now, to try and mine these.

```{r simple mining attempt}
itemFrequency(transcolDB)  ##Individual item support
itemFrequencyPlot(transcolDB,topN=25)  ##Frequency of the top 25

rules<-apriori(transcolDB,parameter=
                   list(support=0.20,
                        confidence =0.4,
                        minlen =2,maxlen=3,
                        target="closed frequent itemsets"))

smallrules<-sample(rules,size=50)

simMatrix<-dissimilarity(smallrules,method="affinity")
## Note that most of these rules have very high affinity to one another. 

```

Extract the patterns of length 3 and compare them to the largepatterns.

```{r break up smallrules}
rulesVector<-labels(smallrules)
support<-support(smallrules,transcolDB,type="relative")
ruleslist<-strsplit(rulesVector,",")
for (i in 1:length(ruleslist))
    {
    for (j in 1:length(ruleslist[[i]]))
        {
        ruleslist[[i]][j]<-gsub("{",
                            "",fixed=TRUE,
                            ruleslist[[i]][j])
        ruleslist[[i]][j]<-gsub("}","",
                            fixed=TRUE,
                            ruleslist[[i]][j])
    
        }
    }
true1<-vector()
true2<-vector()
for (i in 1:50)
    {
    true1[i]<-(ruleslist[[i]][1] %in% largepattern1 &
                  ruleslist[[i]][2] %in% largepattern1
              & ruleslist[[i]][3] %in% largepattern1)
    true2[i]<-(ruleslist[[i]][1] %in% largepattern2 &
                  ruleslist[[i]][2] %in% largepattern2
              & ruleslist[[i]][3] %in% largepattern2)
    }
inpatterns<-(true1 |true2)
support<-cbind(support,true1,true2)
support<-data.frame(support)
support$number<-row.names(support)
for (i in 1:50) {
    if (support$true1[i]==1) {
        support$belong[i]<-"true1"
        }
     else {
         if (support$true2[i]==1) {
            support$belong[i]<-"true2"
        }
        else {
            support$belong[i]<-"None"
            }
        }
    }
support$belong<-as.factor(support$belong)
```

The percentage in largepattern1 is `r mean(true1)` and the percentage in largepattern2 is `r mean(true2)`.

Plot the support levels and the large pattern that a small pattern belongs to.

```{r plot supports}
library(ggplot2)
plot<-ggplot(support,aes(x=number,y=support,color=belong))
plot + geom_point() # Plot support of 3-itemsets, color-coded by the large pattern they belong to.

```

Combine 3-itemsets and then mine with them.

```{r combine itemsets}
set.seed(246)
list6<-list()
for (i in 1:100) {
    list6[[i]]<-unlist(c(sample(ruleslist,1:50),sample(ruleslist,1:50)))
    }  # Sample the ruleslist to extract 2 3-itemsets and combine them. Do this 100 times.
true1<-list()
true2<-list()
for (i in 1:100)
    {
    for (j in 1:length(list6[[i]])) {
        true1[[i]]<-unlist(c(true1[i],(list6[[i]][j] %in% largepattern1)))
        true2[[i]]<-unlist(c(true2[i],(list6[[i]][j] %in% largepattern2)))
        }
    }
mean(true1)
mean(true2)
```